---
output:
  html_document:
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "01-24-2022"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, out.width = "100%", fig.width = 9, fig.align = "center", cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages}
library(dplyr)
library(tidyr)
library(ggplot2)
library(kableExtra)
```

```{r utilities}
source("../../utilities.R")
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

An **outlier** is an observation of a variable that is "extreme" *relative* to a given distribution. The question then is how do we identify which observation(s) is/are outliers?

### Identifying Outliers Using Percentiles

We might define an outlier as any observation below a relatively small percentile, or above a relatively large percentile. One common definition is to identify the "middle 95%" of observations as *not* being outliers. So we can define an outlier as any observation that meets *either* of the following criteria. 

1. The observation is below the 2.5th percentile.
0. The observation is above the 97.5th percentile.

\pagebreak

**Example**: The following plot shows the cumulative distribution of a sample of observations of eruption durations for Old Faithful. (Note: This plot looks slightly different from one we saw earlier because this time I did not round the durations to the nearest 10th of a minute.)
```{r, fig.height = 7}
q <- as.vector(quantile(faithful$eruptions, probs = c(0.025,0.975), type = 2))

p <- ggplot(faithful, aes(x = eruptions)) + theme_minimal()
p <- p + stat_ecdf(geom = "step", pad = TRUE, alpha = 0.5)
p <- p + stat_ecdf(geom = "point", pad = FALSE, size = 0.75)
p <- p + labs(y = "Cumulative Relative Frequency", x = "Duration (min)")
p <- p + geom_hline(yintercept = c(0.025, 0.975), linetype = 2)
p <- p + scale_y_continuous(breaks = c(seq(0, 1, by = 0.1), 0.025, 0.975), minor_breaks = NULL)
p <- p + scale_x_continuous(breaks = c(seq(0, 4.5, by = 0.5), q), minor_breaks = NULL)
plot(p)
```

Below I have "zoomed-in" on the 2.5th and 97.5th percentiles.
```{r, fig.height = 2}
p <- ggplot(faithful, aes(x = eruptions)) + theme_minimal()
p <- p + stat_ecdf(geom = "step", pad = TRUE, alpha = 0.5)
p <- p + stat_ecdf(geom = "point", pad = FALSE, size = 0.75)
p <- p + labs(y = NULL, x = "Duration (min)")
p <- p + geom_hline(yintercept = 0.025, linetype = 2) + geom_hline(yintercept = 0.975, linetype = 2)
p <- p + scale_y_continuous(breaks = c(0.025,0.975))
p <- p + scale_x_continuous(breaks = q)
p <- p + coord_cartesian(xlim = c(1.5,2), ylim = c(0,0.05))
plow <- p

p <- ggplot(faithful, aes(x = eruptions)) + theme_minimal()
p <- p + stat_ecdf(geom = "step", pad = TRUE, alpha = 0.5)
p <- p + stat_ecdf(geom = "point", pad = FALSE, size = 0.75)
p <- p + labs(y = NULL, x = "Duration (min)")
p <- p + geom_hline(yintercept = 0.025, linetype = 2) + geom_hline(yintercept = 0.975, linetype = 2)
p <- p + scale_y_continuous(breaks = c(0.025,0.975))
p <- p + scale_x_continuous(breaks = q)
p <- p + coord_cartesian(xlim = c(4.75,5.25), ylim = c(0.95,1))
pupp <- p

cowplot::plot_grid(plow, pupp, ncol = 2)
```

\pagebreak

**Example**: Cumulative distributions and box plots of the data from the study on creativity and motivation. What scores would be outliers for each distribution if we use the 2.5th and 97.5th percentiles?
```{r, fig.height = 10}
p <- ggplot(Sleuth3::case0101, aes(x = Score, color = Treatment)) + theme_classic()
p <- p + labs(y = "Cumulative Relative Frequency", color = "Motivation")
p <- p + theme(panel.grid.major = element_line(colour = "black", linetype = 3, size = 0.1))
p <- p + stat_ecdf(geom = "step", pad = TRUE) 
p <- p + stat_ecdf(geom = "point", pad = FALSE, size = 0.75)
p <- p + scale_x_continuous(breaks = seq(0, 30, by = 1))
p <- p + scale_y_continuous(breaks = seq(0, 1, by = 0.05/2), limits = c(0,1))
p <- p + theme(legend.position = c(0.9, 0.3))
plot(p)
```

\pagebreak

### Identifying Outliers Using the Empirical Rule

For an approximately normal distribution, we can use the empirical rule to find the "middle 95%" of observations as those observations within two standard deviations of the mean. So an outlier is any observation that meets *either* of the following two criteria.

1. The observation is less than $\bar{x} - 2s$ (i.e., $x < \bar{x} - 2s$).
0. The observation is greater than $\bar{x} + 2s$ (i.e., $x > \bar{x} + 2s$).

```{r}
set.seed(123)
n <- 500
d <- data.frame(x = round(rnorm(n, 50, 10)))
d$outlier <- FALSE
m <- round(mean(d$x))
s <- round(sd(d$x))
d$z <- with(d, (x - m)/s)
d$outlier[abs(d$z) > 2] <- TRUE
```

**Example**: Consider the following approximately normal distribution of a variable $x$. The distribution has a mean of `r m` and a standard deviation of `r s`. How do we know that, say, 25 and 72 are outliers, but that 36 and 62 are not?
```{r, fig.height = 4.25}
labels <- seq(20, 85, by = 1)
for (i in 1:length(labels)) {
  if (labels[i] %% 5) {
    labels[i] <- NA
  }
}
labels[is.na(labels)] <- ""

p <- ggplot(d, aes(x = x, fill = outlier)) + theme_classic()
p <- p + geom_dotplot(binwidth = 1, method = "histodot")
p <- p + theme(legend.position = "none") + noyaxis
p <- p + scale_fill_manual(values = c("white","black"))
p <- p + scale_x_continuous(breaks = seq(20, 85, by = 1), labels = labels)
plot(p)
```

```{r}
set.seed(107)
n <- 500
m <- 100
s <- 12
d <- data.frame(x = round(rnorm(n, m, s),1))
d$outlier <- FALSE
d$z <- with(d, (x - mean(x))/sd(x))
d$outlier[abs(d$z) > 2] <- TRUE
```
**Example**: Consider the following distribution of a quantitative variable $x$. The distribution has a mean of `r m` and a standard deviation of `r s`. 
```{r, fig.height = 3}
labels <- seq(50, 150, by = 1)
for (i in 1:length(labels)) {
  if (labels[i] %% 5) {
    labels[i] <- NA
  }
}
labels[is.na(labels)] <- ""
p <- ggplot(d, aes(x = x)) + theme_classic()
p <- p + geom_dotplot(binwidth = 1, method = "histodot", fill = "white")
p <- p + theme(legend.position = "none") + noyaxis
p <- p + scale_x_continuous(breaks = seq(50, 150, by = 1), labels = labels)
plot(p)
```
Which observations are outliers?

**Example**: Suppose that the distribution of the heights of Hobbits in the Shire is approximately normal/bell-shaped with a mean of 90 cm and a standard deviation of 10 cm. Frodo is 107 cm tall, and Pippin (after consuming Ent-draughts) is 137 cm. Are either of these Hobbits outliers? How short or tall would a Hobbit need to be to be an outlier? 

\pagebreak

### Identifying Outliers Using the Five Number Summary

The empirical rule only applies to approximately normal distributions. For a non-normal distribution a similar approach we can use is based on the five number summary. Here an outlier is any observation that meets either of the following two criteria.

1. The observation is less than $Q_1 - 1.5(Q_3-Q_1)$. That is, $x$ is an outlier if $x < Q_1 - 1.5(Q_3-Q_1)$.
0. The observation is greater than $Q_3 + 1.5(Q_3-Q_1)$. That is, $x$ is an outlier if $x > Q_3 + 1.5(Q_3 - Q_1)$. 

Recall that $Q_3-Q_1$ is the *interquartile range* (a measure of variability). 

```{r}
set.seed(124)
n <- 100
d <- data.frame(x = round(rt(n, df = 5) + 10, 1))
d$outlier <- FALSE
q1 <- quantile(d$x, 0.25, type = 2)
q2 <- quantile(d$x, 0.50, type = 2)
q3 <- quantile(d$x, 0.75, type = 2)
d$outlier[d$x < q1 - 1.5 * (q3 - q1)] <- TRUE
d$outlier[d$x > q3 + 1.5 * (q3 - q1)] <- TRUE
lower <- q1 - 1.5 * (q3 - q1)
upper <- q3 + 1.5 * (q3 - q1)
```

**Example**: Consider the following distribution of a variable $x$. The first quartile is $Q_1 =$ `r q1` and the third quartile is $Q_3 =$ `r q3`. Which observations are outliers? 
```{r, fig.height = 2.5}
f <- function(x) {
  r <- quantile(x, probs = c(0, 0.25, 0.5, 0.75, 1), type = 2)
  names(r) <- c("ymin", "lower", "middle", "upper", "ymax")
  return(r)
}

p <- ggplot(d, aes(x = x, fill = outlier)) + theme_classic()
p <- p + geom_dotplot(binwidth = 0.1, method = "histodot")
p <- p + scale_fill_manual(values = c("white","black"))
p <- p + scale_x_continuous(breaks = seq(5, 15, by = 1), limits = c(5,15))
p <- p + theme(legend.position = "none") + noyaxis
p <- p + annotate("segment", x = lower, xend = lower, y = 0, yend = 1)
p <- p + annotate("segment", x = upper, xend = upper, y = 0, yend = 1)
pd <- p

p <- ggplot(d, aes(x = 2, y = x)) + theme_classic() + coord_flip()
p <- p + stat_summary(fun.data = f, geom = "boxplot", fatten = 1) + noyaxis
p <- p + scale_y_continuous(breaks = as.vector(c(lower, upper, quantile(d$x, c(0, 0.25, 0.5, 0.75, 1), type = 2))), limits = c(5,15))
p <- p + xlim(1.5,2.5)
p <- p + annotate("segment", y = lower, yend = lower, x = 1.5, xend = 2.5)
p <- p + annotate("segment", y = upper, yend = upper, x = 1.5, xend = 2.5)
p <- p + theme(axis.text = element_text(size = 8))
pb <- p

cowplot::plot_grid(pd, pb, ncol = 1, align = "v", rel_heights = c(1,1))
```

```{r}
set.seed(124)
n <- 100
d <- data.frame(x = round(rt(n, df = 5) + 50, 1))
d$outlier <- FALSE
q1 <- quantile(d$x, 0.25, type = 2)
q3 <- quantile(d$x, 0.75, type = 2)
```

**Example**: Consider the following distribution of a variable $x$. The first quartile is $Q_1$ = `r q1` and the third quartile is $Q_3$ = `r q3`. Which observations are outliers? 
```{r, fig.height = 1.5}
p <- ggplot(d, aes(x = x)) + theme_classic()
p <- p + geom_dotplot(binwidth = 0.1, method = "histodot", fill = "white")
p <- p + scale_x_continuous(breaks = seq(45, 55, by = 1))
p <- p + theme(legend.position = "none") + noyaxis
plot(p)
```

```{r}
set.seed(124)
n <- 100
d <- data.frame(x = round(rgamma(n, 3, 1/4)))
d$outlier <- FALSE
q1 <- quantile(d$x, 0.25, type = 2)
q2 <- quantile(d$x, 0.50, type = 2)
q3 <- quantile(d$x, 0.75, type = 2)
```

**Example**: Consider the following distribution of a quantitative variable $x$. The first quartile is $Q_1$ = `r q1` and the third quartile is $Q_3$ = `r q3`. Which observations are outliers? 
```{r, fig.height = 3.5}
p <- ggplot(d, aes(x = x)) + theme_classic()
p <- p + geom_dotplot(binwidth = 1, method = "histodot", fill = "white")
p <- p + scale_x_continuous(breaks = seq(0, max(d$x), by = 1), limits = c(0, max(d$x)))
p <- p + theme(legend.position = "none") + noyaxis
plot(p)
```

\pagebreak

## Resistant (and Non-Resistant) Summary Measures

To say that a summary measure is **resistant** means that it is not (much) influenced by extreme outliers. 

*Resistant* summary measures include the *median* and *interquartile range*. 

Summary measures that are *not* resistant include the *mean*, *variance*, *standard deviation*, and *range*. 

## Margin of Error

**Example**: Consider a forestry survey to estimate the mean volume of trees in a given region. The goal of such a survey would be to use the mean from the *sample* of observations of tree volume (a *statistic*) as an *estimate* of the mean from the *population* of observations of tree volume (a *parameter*). This is an example of *statistical inference*.

```{r, fig.height = 4, fig.width = 9}
set.seed(100)

N <- 350
n <- 10

d <- data.frame(volume = rlnorm(N, mean(log(trees$Volume)), sd(log(trees$Volume)))) %>% 
  filter(volume > 5 & volume < 90) %>% mutate(volume = volume - mean(volume) + 30)

m <- round(mean(d$volume))
s <- round(sd(d$volume))

N <- nrow(d)

d <- d %>% mutate(select = sample(rep(c(0,1), c(N-n,n)))) %>% mutate(select = factor(select))

p <- ggplot(d, aes(x = round(volume), fill = select)) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() 
p <- p + scale_fill_manual(values = c("white","black"))
p <- p + guides(fill = "none") + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + geom_point(aes(x = mean(volume), y = -0.05, fill = NULL), shape = 17)
p1 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Distribution of Observations in Population")

p <- ggplot(subset(d, select == 1), aes(x = round(volume))) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + geom_point(aes(x = mean(d$volume[d$select == 1]), y = -0.2, fill = NULL), shape = 17)
p2 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Distribution of Observations in Sample")

cowplot::plot_grid(p1, p2, align = "v", ncol = 1, rel_heights = c(2, 1))

m.sample <- round(mean(d$volume[d$select == 1]),1)
```

The means for each distribution are shown by the triangles. The distribution of observations in the *population* has a mean of `r m`. The distribution of observations in the *sample* has a mean of `r m.sample`. 

But clearly the estimate we get would depends on the sample. We could *in theory* consider a *distribution of estimates from many samples*. This is an approximation of what is called a *sampling distribution* (more on that later).

```{r, fig.width = 9, fig.height = 6}
d <- d %>% mutate(select = sample(rep(c(0,1), c(N-n,n)))) %>% mutate(select = factor(select)) %>% 
  mutate(m = mean(volume[select == 1]))

p <- ggplot(subset(d, select == 1), aes(x = round(volume))) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + geom_point(aes(x = m, y = -0.2, fill = NULL), shape = 17)
p3 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Distribution of Observations in Another Sample")

d <- d %>% mutate(select = sample(rep(c(0,1), c(N-n,n)))) %>% mutate(select = factor(select)) %>% 
  mutate(m = mean(volume[select == 1]))

p <- ggplot(subset(d, select == 1), aes(x = round(volume))) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + geom_point(aes(x = m, y = -0.2, fill = NULL), shape = 17)
p4 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Distribution of Observations in Another Sample")

d <- d %>% mutate(select = sample(rep(c(0,1), c(N-n,n)))) %>% mutate(select = factor(select)) %>% 
  mutate(m = mean(volume[select == 1]))

p <- ggplot(subset(d, select == 1), aes(x = round(volume))) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + geom_point(aes(x = m, y = -0.2, fill = NULL), shape = 17)
p5 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Distribution of Observations in Another Sample")

r <- 100000
y <- rep(NA, r)
for (i in 1:r) {
  y[i] <- mean(sample(d$volume, n))
}
w <- 1

p <- ggplot(data.frame(x = y), aes(x = x, y = ..density.. * w)) + theme_classic()
p <- p + geom_histogram(breaks = seq(0, 90, by = 0.5), fill = "white", color = "black")
p <- p + labs(x = "Mean", y = "Relative Frequency") + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + ggtitle("Distribution of Means from 500,000 Samples")

cowplot::plot_grid(p3, p4, p5, p, ncol = 1, align = "v", rel_heights = c(1, 1, 1, 2))
```

```{r, fig.height = 3, fig.width = 9, warning = FALSE}
p <- ggplot(data.frame(x = y), aes(x = x, y = ..density.. * w)) + theme_classic()
p <- p + geom_histogram(breaks = seq(0, 90, by = 0.5), fill = "white", color = "black")
p <- p + labs(x = "Mean", y = "Relative Frequency") + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(10, 50))
p <- p + ggtitle("Distribution of Means from 500,000 Samples")
plot(p)

m <- round(mean(y))
s <- round(sd(y))
```
This distribution has a mean of `r m` and a standard deviation of `r s`. Notice that the mean of this distribution is equal to the parameter being estimated. According to the empirical rule, between what two values would we find about 95% of the estimates? 

\vspace{1cm}

The **margin of error** is the largest distance between the parameter and an estimate that is *not an outlier*. What is the margin of error here? 