---
output:
  html_document:
    theme: readable
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "10-22-2021"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{array}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, fig.align = "center", out.width = "100%", fig.width = 9, cache = TRUE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages}
library(dplyr)
library(tidyr)
library(ggplot2)
library(kableExtra)
```

```{r utilities}
source("../../utilities.R")
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

## Statistical Test Errors

The *decision* to reject or not reject $H_0$ may be a correct or incorrect decision.
```{r}
d <- data.frame(Reality = c("$H_0$ true","$H_0$ false"),
  a = c("correct decision","type II error"),
  b = c("type I error","correct decision"))
names(d)[2:3] <- c("Do Not Reject $H_0$","Reject $H_0$")
ktbl(d) %>% add_header_above(c(" " = 1, "Decision" = 2))
```
We have two types of errors:

1. A **type I error** occurs when the null hypothesis is *true* but it is *rejected* --- i.e., *rejecting* a *true* null hypothesis.
2. A **type II error** occurs when the null hypothesis is *false* but it is *not rejected* --- i.e., *failing to reject* a *false* null hypothesis.

**Example**: Recall the twin study that examined the relationship between schizophrenia and left hippocampus volume. Suppose the hypotheses are $H_0\!: \mu = 0$ (there is no relationship) and $H_a\!: \mu > 0$ (there is a relationship).
```{r}
d <- data.frame(Reality = c("there is no relationship","there is a relationship"),
  a = c("correctly conclude there is no relationship","incorrectly conclude there is no relationship"), b = c("incorrectly conclude there is a relationship","correctly conclude there is a relationship"))
names(d)[2:3] <- c("Do Not Reject $H_0$","Reject $H_0$")
ktbl(d, align = "lcc") %>% add_header_above(c(" " = 1, "Decision" = 2)) %>%  column_spec(column = 1, bold = TRUE)
```
We rejected $H_0$. What kind of error might we have made?

**Example**: Recall the study with the cross-over design that investigated if garlic repels ticks. Suppose the hypotheses are $H_0\!: p = 0.5$ (garlic is not effective) versus $H_a\!: p > 0.5$ (garlic is effective).
```{r}
d <- data.frame(Reality = c("garlic is not effective","garlic is effective"),
  a = c("correctly conclude that garlic is ineffective","incorrectly conclude that garlic is ineffective"),
  b = c("incorrectly conclude that garlic is effective","correctly conclude that garlic is effectve"))
names(d)[2:3] <- c("Do Not Reject $H_0$","Reject $H_0$")
ktbl(d, align = "lcc") %>% add_header_above(c(" " = 1, "Decision" = 2)) %>%  column_spec(column = 1, bold = TRUE)
```
We did not reject $H_0$. What kind of error might we have made?

## Probability of a Type I Error

The probability of a type I error is the probability of *rejecting* $H_0$ when it is *true*.

**Example**: Suppose we have the hypotheses $H_0\!: \mu = 0$ versus $H_a\!: \mu > 0$ and plan to use a significance level of $\alpha$ = 0.05. The *critical value* of $t$ is the value of the test statistic with a p-value *equal* to the significance level. Assume a sample size of $n$ = 10.
```{r, fig.height = 3, fig.width = 9}
par(mai = c(0.75,0,0,0), cex = 0.9)
x <- seq(-4, 4, length = 1000)
y <- dt(x, df = 9)
a <- 0.05
plot(x, y, type = "l", yaxt = "n", ylab = "", xlab = "t", bty = "n", xaxt = "n", ylim = c(0, dt(0, 9)))
axis(1, lwd.tick = 0, labels = FALSE)
axis(1, at = c(0, qt(1-a, 9)), labels = as.character(c(0, round(qt(1-a, 9),3))))
trtools::aucpoly(x, function(x) dt(x, df = 9), qt(1-a, 9), max(x), col = scales::alpha(grey(0.75), 0.5))
```
So we can state the decision rule as follows.

1. If $t \ge `r round(qt(1-a, 9), 3)`$ then $\text{$p$-value} \le \alpha$ so *reject* $H_0$.
2. If $t < `r round(qt(1-a, 9), 3)`$ then $\text{$p$-value} > \alpha$ so *do not reject* $H_0$.

Thus the probability of a type I error is the probability of rejecting $H_0$ when $H_0$ is true, which is $P(t \ge `r round(qt(1-a, 9), 3)` | H_0) = \alpha$. Thus, *the probability of rejecting the null hypothesis when it is true (i.e., a type I error) equals $\alpha$.*

## Probability of a Type II Error

The probability of a type II error is the probability of *not rejecting* $H_0$ when it is *false*. 

**Example**: Suppose again that we have the hypotheses $H_0\!: \mu = 0$ versus $H_a\!: \mu > 0$ and plan to use a significance level of $\alpha$ = 0.05. The *critical value* of $t$ is the value of the test statistic with a p-value *equal* to the significance level. Assume a sample size of $n$=10. But now suppose that *in reality* $\mu > 0$ (e.g., $\mu = 1)$. Note that the sampling distribution of the test statistic when $H_0$ is true is shown by the dotted line, while the sampling distribution of the test statistic when $H_0$ is false is shown by the solid line. 
```{r, fig.height = 3, fig.width = 9}
n <- 10
tc <- qt(1-0.05, df = n-1)
t <- sort(c(tc, seq(-5, 10, length = 1000)))
d0 <- dt(t, df = n-1)
t.acc <- t[t <= tc]
t.rej <- t[t >= tc]

ncp <- 1*sqrt(n)/1
d1 <- dt(t, df = n - 1, ncp = ncp)

par(mai = c(0.75, 0, 0, 0), cex = 0.9)

plot(t, d1, type = "l", bty = "n", yaxt = "n", ylab = "", xaxt = "n", xlab = "t", ylim = c(0, max(c(d0,d1))))
lines(t, d0, type = "l", lty = 2)
axis(1, lwd.tick = 0, labels = FALSE)
axis(1, at = c(0, tc), labels = c("0", round(tc, 3)))
polygon(x = c(t.acc, tc), y = c(dt(t.acc, df = n-1, ncp = ncp), 0), col = scales::alpha(grey(0.5), 0.5))
polygon(x = c(t.rej, max(t.rej), tc), y = c(dt(t.rej, df = n-1, ncp = ncp), 0, 0), col = scales::alpha(grey(0.75), 0.5))

tc <- qt(1-0.05/2, df = n-1)
t.acc <- t[abs(t) <= tc]
```
So the probability of a type II error (i.e., the probability of *not rejecting* $H_0$ when it is *false*) here is $P(t < 1.833 | H_a)$. 

It is not as simple to compute the probability of a type II error because it depends on several factors.

## Effect of $\alpha$ on Error Probabilities

The probability of a type I error is the *light* grey area, and the probability of a type II error is the *dark* grey area. 

```{r, fig.height = 3, fig.width = 9}
n <- 10
a <- 0.1
m0 <- 0
m1 <- 0.75
tc <- qt(1-a, df = n-1)
t <- sort(c(tc, seq(-5, 10, length = 1000)))
v <- 1
d0 <- dt(t, df = n-1)
d1 <- dt(t, df = n-1, ncp = (m1-m0)*sqrt(n)/v)
t.acc <- c(t[t <= tc])
t.rej <- c(t[t >= tc])

par(mai = c(0.75, 0, 0, 0), cex = 0.9)

plot(t, d0, type = "l", bty = "n", yaxt = "n", ylab = "", xaxt = "n", xlab = "", ylim = c(0, max(c(d0,d1))), lty = 2)
lines(t, d1)
axis(1, lwd.tick=0, labels=FALSE)
axis(1, at = c(0, tc), labels = c("0", round(tc, 3)))
polygon(x = c(t.acc, tc), y = c(dt(t.acc, df = n-1, ncp = (m1-m0)*sqrt(n)/v), 0), col = scales::alpha(grey(0.5), 0.5), border = NA)
polygon(x = c(t.rej, max(t.rej), tc), y = c(dt(t.rej, df = n - 1), 0, 0), col = scales::alpha(grey(0.75), 0.5), border = NA)

text(7, 0.25, paste("Significance Level:", a))
```
```{r, fig.height = 3, fig.width = 9}
n <- 10
a <- 0.05
m0 <- 0
m1 <- 0.75
tc <- qt(1-a, df = n-1)
t <- sort(c(tc, seq(-5, 10, length = 1000)))
v <- 1
d0 <- dt(t, df = n-1)
d1 <- dt(t, df = n-1, ncp = (m1-m0)*sqrt(n)/v)
t.acc <- c(t[t <= tc])
t.rej <- c(t[t >= tc])

par(mai = c(0.75, 0, 0, 0), cex = 0.9)

plot(t, d0, type = "l", bty = "n", yaxt = "n", ylab = "", xaxt = "n", xlab = "", ylim = c(0, max(c(d0,d1))), lty = 2)
lines(t, d1)
axis(1, lwd.tick=0, labels=FALSE)
axis(1, at = c(0, tc), labels = c("0", round(tc, 3)))
polygon(x = c(t.acc, tc), y = c(dt(t.acc, df = n-1, ncp = (m1-m0)*sqrt(n)/v), 0), col = scales::alpha(grey(0.5), 0.5), border = NA)
polygon(x = c(t.rej, max(t.rej), tc), y = c(dt(t.rej, df = n - 1), 0, 0), col = scales::alpha(grey(0.75), 0.5), border = NA)

text(7, 0.25, paste("Significance Level:", a))
```
```{r, fig.height = 3, fig.width = 9}
n <- 10
a <- 0.01
m0 <- 0
m1 <- 0.75
tc <- qt(1-a, df = n-1)
t <- sort(c(tc, seq(-5, 10, length = 1000)))
v <- 1
d0 <- dt(t, df = n-1)
d1 <- dt(t, df = n-1, ncp = (m1-m0)*sqrt(n)/v)
t.acc <- c(t[t <= tc])
t.rej <- c(t[t >= tc])

par(mai = c(0.75, 0, 0, 0), cex = 0.9)

plot(t, d0, type = "l", bty = "n", yaxt = "n", ylab = "", xaxt = "n", xlab = "", ylim = c(0, max(c(d0,d1))), lty = 2)
lines(t, d1)
axis(1, lwd.tick=0, labels=FALSE)
axis(1, at = c(0, tc), labels = c("0", round(tc, 3)))
polygon(x = c(t.acc, tc), y = c(dt(t.acc, df = n-1, ncp = (m1-m0)*sqrt(n)/v), 0), col = scales::alpha(grey(0.5), 0.5), border = NA)
polygon(x = c(t.rej, max(t.rej), tc), y = c(dt(t.rej, df = n - 1), 0, 0), col = scales::alpha(grey(0.75), 0.5), border = NA)

text(7, 0.25, paste("Significance Level:", a))
```

If we decrease $\alpha$ we will (a) decrease the probability of a type I error and (b) increase the probability of a type II error.

If we increase $\alpha$ we will (a) increase the probability of a type I error and (b) decrease the probability of a type II error.
