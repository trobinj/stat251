---
output:
  html_document:
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "01-31-2022"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, out.width = "100%", fig.width = 9, fig.align = "center", cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages}
library(dplyr)
library(tidyr)
library(ggplot2)
library(kableExtra)
```

```{r utilities}
source("../../utilities.R")
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

## Probability and Relative Frequency

*Probability* is a measurement of the "likelihood" of an event as a number between 0 and 1. These measurements follow the mathematical rules of *probability theory*. 

How can we connect probabilities with empirical observations? The *Law of Large Numbers* states that a *relative frequency* will tend to "approach" (in some sense) the *probability* of an event as the number of observations increases.

**Example**: Consider rolling a 4-sided die many times and looking at the distribution of the sides.

```{r, fig.height = 4, fig.width = 9}
set.seed(123)
n <- 4
N <- 1000
p <- rep(1/n, n)

d <- data.frame(roll = 1:N, y = sample(1:n, N, replace = TRUE, prob = p)) %>%
  mutate(p1 = cumsum(y == 1)/roll, p2 = cumsum(y == 2)/roll, 
    p3 = cumsum(y == 3)/roll, p4 = cumsum(y == 4)/roll) %>% select(roll, p1:p4) %>% 
  pivot_longer(p1:p4, names_to = "side", values_to = "rf") %>%
  mutate(side = factor(rep(1:4, N)))

p <- ggplot(d, aes(x = roll, y = rf, color = side))
p <- p + labs(y = "Relative Frequency", x = "Roll", color = "Side")
p <- p + theme_classic() + ggtitle("Fair 4-Sided Die")
p <- p + theme(legend.position = c(0.9, 0.8))
p <- p + geom_hline(yintercept = 0.25, linetype = 3) + geom_line()

p1 <- p

d <- d %>% group_by(side) %>% filter(roll == N)

p <- ggplot(d, aes(x = side, y = rf, color = side))
p <- p + geom_point(show.legend = FALSE)
p <- p + geom_segment(aes(xend = side, yend = 0), show.legend = FALSE)
p <- p + theme_classic() + labs(x = "Side", y = NULL)
p <- p + ylim(0,1)

p2 <- p

cowplot::plot_grid(p1, p2, ncol = 2, rel_widths = c(2,1), align = "h")

set.seed(123)
n <- 4
N <- 1000
p <- c(0.4,0.3,0.2,0.1)

d <- data.frame(roll = 1:N, y = sample(1:n, N, replace = TRUE, prob = p)) %>%
  mutate(p1 = cumsum(y == 1)/roll, p2 = cumsum(y == 2)/roll, 
    p3 = cumsum(y == 3)/roll, p4 = cumsum(y == 4)/roll) %>% select(roll, p1:p4) %>% 
  pivot_longer(p1:p4, names_to = "side", values_to = "rf") %>%
  mutate(side = factor(rep(1:4, N)))

p <- ggplot(d, aes(x = roll, y = rf, color = side))
p <- p + labs(y = "Relative Frequency", x = "Roll", color = "Side")
p <- p + theme_classic() + ggtitle("Loaded 4-Sided Die")
p <- p + theme(legend.position = c(0.9, 0.8))
p <- p + geom_hline(yintercept = c(0.1,0.2,0.3,0.4), linetype = 3) + geom_line()
p <- p + scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1))

p1 <- p

d <- d %>% group_by(side) %>% filter(roll == N)

p <- ggplot(d, aes(x = side, y = rf, color = side))
p <- p + geom_point(show.legend = FALSE)
p <- p + geom_segment(aes(xend = side, yend = 0), show.legend = FALSE)
p <- p + theme_classic() + labs(x = "Side", y = NULL)
p <- p + scale_y_continuous(breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1), limits = c(0,1))

p2 <- p

cowplot::plot_grid(p1, p2, ncol = 2, rel_widths = c(2,1), align = "h")
```

In a *survey* the relative frequencies for the distribution of the *population* of observations become probabilities if we select units *at random*. 

**Example**: Consider a survey of tree volume. 

```{r, fig.height = 5, fig.width = 9}
p <- ggplot(trees, aes(x = round(Volume))) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() + noyaxis
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p1 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Data Distribution")

set.seed(102)

N <- 350
n <- 31

d <- data.frame(volume = c(trees$Volume, rlnorm(N, mean(log(trees$Volume)), sd(log(trees$Volume)))))
d <- dplyr::filter(d, volume > 5 & volume < 90)

N <- nrow(d)

d$select <- sample(rep(c(0,1), c(N-n,n)))
d$volume[d$select == 1] <- trees$Volume
d$select <- factor(d$select)

p <- ggplot(d, aes(x = round(volume), fill = select)) 
p <- p + geom_dotplot(binwidth = 1) + theme_classic() + noyaxis
p <- p + scale_fill_manual(values = c("white","black"))
p <- p + guides(fill = "none")
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p2 <- p + labs(x = "Volume (Cubic Feet)") + ggtitle("Distribution of Population of Observations")

d <- d %>% mutate(volume = round(volume)) %>% group_by(volume) %>% 
  summarize(n = n()) %>% mutate(relfreq = n/sum(n))

p <- ggplot(d, aes(x = volume, y = relfreq))
p <- p + geom_point()
p <- p + theme_classic()
p <- p + geom_segment(aes(xend = volume, yend = 0))
p <- p + scale_x_continuous(breaks = seq(0, 90, by = 10), limits = c(0, 90))
p <- p + labs(x = "Volume (Cubic Feet)", y = "Relative Frequency\n and Probability")
p3 <- p + labs(x = "Volume (Cubic Feet)")

cowplot::plot_grid(p2, p3, align = "v", ncol = 1, rel_heights = c(1,1))
```

In an *experiment* the probabilities are determined by the underlying process that produces the observations.

**Example**: Suppose we are studying the distance that a toy trebuchet will throw a projectile.

```{r}
x <- 1:3
p <- c(0.1,0.3,0.6)
d <- expand.grid(x1 = x, x2 = x, x3 = x)
d$xbar <- apply(d, 1, mean)
d$prob <- apply(expand.grid(p1 = p, p2 = p, p3 = p), 1, prod)
d <- d %>% group_by(xbar) %>% summarize(prob = sum(prob))
d$label <- format(d$prob, nsmall = 3)

popdist <- data.frame(Distance = 1:3, Probability = p)
smpdist <- data.frame(Distance = round(d$xbar, 2), Probability = d$label)
names(smpdist) <- c("$\\bar{x}$", "$P(\\bar{x})$")
```

First consider observing the distance ($x$) of *one* throw.
```{r, fig.height = 3, fig.width = 9}
p <- ggplot(popdist, aes(x = Distance, y = Probability))
p <- p + geom_point() + theme_classic()
p <- p + geom_segment(aes(xend = Distance, yend = 0))
p <- p + scale_x_continuous(breaks = popdist$Distance)
p <- p + labs(x = tex("Distance $(x)$"))
p <- p + scale_y_continuous(breaks = seq(0, 1, by = 0.1))
plot(p)
```

Now consider observing the *mean* distance (i.e., $\bar{x}$) of a sample of $n$ = 3 throws.
```{r, fig.height = 3, fig.width = 9}
p <- ggplot(d, aes(x = xbar, y = prob))
p <- p + geom_point() + theme_classic()
p <- p + geom_segment(aes(xend = xbar, yend = 0))
p <- p + scale_x_continuous(breaks = d$xbar, labels = round(d$xbar, 2))
p <- p + labs(x = tex("Mean Distance $(\\bar{x})$"), y = "Probability")
p <- p + scale_y_continuous(limits = c(0, 0.35), breaks = c(0.1, 0.2, 0.3))
plot(p)
```

Now consider observing the *mean* distance (i.e., $\bar{x}$) of a sample of $n$ = 10 throws.
```{r, fig.height = 3, fig.width = 9}
x <- 1:3
p <- c(0.1,0.3,0.6)
d <- expand.grid(x1 = x, x2 = x, x3 = x, x4 = x, x5 = x, x6 = x, x7 = x, x8 = x, x9 = x, x10 = x)
d$xbar <- apply(d, 1, mean)
d$prob <- apply(expand.grid(p1 = p, p2 = p, p3 = p, p4 = p, p5 = p, p6 = p, p7 = p, p8 = p, p9 = p, p10 = p), 1, prod)
d <- d %>% group_by(xbar) %>% summarize(prob = sum(prob))
d$label <- format(d$prob, nsmall = 3)
p <- ggplot(d, aes(x = xbar, y = prob))
p <- p + geom_point() + theme_classic()
p <- p + geom_segment(aes(xend = xbar, yend = 0))
p <- p + scale_x_continuous(breaks = d$xbar, labels = round(d$xbar, 2))
p <- p + labs(x = tex("Mean Distance $(\\bar{x})$"), y = "Probability")
p <- p + scale_y_continuous(limits = c(0, 0.35), breaks = c(0.1, 0.2, 0.3))
plot(p)
```

**Example**: Suppose we are studying the "preference" of female platies for males with clear versus yellow tails. Consider observing (a) the apparent preference from one observation and (b) the *proportion* of observations out of $n$ = 3 observations where the yellow-tailed male is preferred.

```{r, fig.height = 3, fig.width = 9}
dsmp <- data.frame(x = c("clear","yellow"), y = c(0.3,0.7))
dpop <- data.frame(x = c(0:3)/3, y = dbinom(0:3, 3, 0.7))

psmp <- ggplot(dsmp, aes(x = x, y = y)) + theme_classic()
psmp <- psmp + geom_point() + geom_segment(aes(yend = 0, xend = x))
psmp <- psmp + labs(x = "Preference", y = "Probability") + ylim(0, 0.7)

ppop <- ggplot(dpop, aes(x = x, y = y)) + theme_classic()
ppop <- ppop + geom_point() + geom_segment(aes(yend = 0, xend = x))
ppop <- ppop + labs(x = tex("Proportion Preferring Yellow-Tailed Male"), y = "Probability") + ylim(0, 0.7)
ppop <- ppop + scale_x_continuous(breaks = c(0:3)/3, labels = MASS::fractions(c(0:3)/3))

cowplot::plot_grid(psmp, ppop, align = "h", ncol = 2)
```

## Random Variables and Probability Distributions

A **random variable** occurs when we assign values to an *event*. An *event* corresponds to a particular *outcome* of a random process. Distance, mean distance, preference, and proportion preferring yellow-tailed male are all *random variables* in the examples above. Random variables can be *quantitative* or *categorical*. 

Types of *Quantitative* Random Variables:

1. **Discrete**. A random variable is *discrete* if the possible values are *countable*.
2. **Continuous**. A random variable is *continuous* if the possible values are *not countable*. 

The **probability distribution** of a *discrete* random variable consists of (a) the *possible values* of the random variable and (b) their *probabilities*. The distribution can be shown using a plot (as shown earlier) or a table (as shown below).

**Example**: Here are the probability distributions of one observation of the distance a trebuchet throws ($x$), and the mean distance in a sample of $n$ = 3 throws ($\bar{x}$).

```{r}
x <- 1:3
p <- c(0.1,0.3,0.6)
d <- expand.grid(x1 = x, x2 = x, x3 = x)
d$xbar <- apply(d, 1, mean)
d$prob <- apply(expand.grid(p1 = p, p2 = p, p3 = p), 1, prod)
d <- d %>% group_by(xbar) %>% summarize(prob = sum(prob))
d$label <- format(d$prob, nsmall = 3)

popdist <- data.frame(Distance = 1:3, Probability = p)
smpdist <- data.frame(Distance = round(d$xbar, 2), Probability = d$label)

names(popdist) <- c("$x$", "$P(x)$")
names(smpdist) <- c("$\\bar{x}$", "$P(\\bar{x})$")

ktbl(popdist)
ktbl(smpdist)
```

**Example**: Here are the probability distributions of one observation of female platy preference ($x$), and the proportion of observations out of $n$ = 3 where the yellow-tailed male is preferred ($\hat{p}$). 

```{r}
d <- data.frame(x = c("clear","yellow"), p = c(0.3,0.7))
names(d) <- c("$x$", "$P(x)$")
ktbl(d)
d <- data.frame(x = c("0","1/3","2/3","1"), p = dbinom(0:3, 3, 0.7))
names(d) <- c("$\\hat{p}$", "$P(\\hat{p})$")
ktbl(d)
```

Two Important Probability Distributions in Statistical Inference

1. The probability distribution of a *single observation* (a **population distribution**).
2. The probability distribution of a *statistic* (a **sampling distribution**). 

## Mean of a Random Variable (Discrete Case)

The mean of a *discrete* random variable is
$$
  \mu = \sum_x xP(x),
$$
where $x$ denotes a value of the random variable and $P(x)$ denotes the probability of that value.[^mean] Note that the $x$ below the summation sign here indicates that we sum over all values of $x$. 

The Law of Large Numbers implies that as the number of observations of a random variable increases, their mean ($\bar{x}$) will tend to "approach" (in some sense) $\mu$. 

[^mean]: We can say that "$\mu$ is the mean of the probability distribution of the random variable" or, more simply, "$\mu$ is the mean of the random variable." Similarly we can say that "$\sigma$ is the standard deviation of a probability distribution" or that "$\sigma$ is the standard deviation of a random variable.

**Example**: Consider the probability distribution of an observation of a single throw of the trebuchet (a *population distribution*). 
```{r}
x <- 1:3
p <- c(0.1,0.3,0.6)
d <- expand.grid(x1 = x, x2 = x, x3 = x)
d$xbar <- apply(d, 1, mean)
d$prob <- apply(expand.grid(p1 = p, p2 = p, p3 = p), 1, prod)
d <- d %>% group_by(xbar) %>% summarize(prob = sum(prob))
d$label <- format(d$prob, nsmall = 3)
popdist <- data.frame(Distance = 1:3, Probability = p)
smpdist <- data.frame(Distance = round(d$xbar, 2), Probability = d$label)
names(popdist) <- c("$x$","$P(x)$")
names(smpdist) <- c("$\\bar{x}$", "Probability")
ktbl(popdist)
```
We can confirm that the mean of the random variable $x$ is $\mu$ = `r crossprod(x,p)` m.

\vspace{5cm}

**Example**: Consider the probability distribution of the proportion of female platies that prefer the yellow-tailed male from a sample $n$ = 3 observations (a *sampling distribution*).
```{r}
d <- data.frame(Proportion = c("0","1/3","2/3","1"), Probability = dbinom(0:3, 3, 0.7))
names(d) <- c("$\\hat{p}$","$P(\\hat{p})$")
ktbl(d)
```
We can confirm that the mean of the random variable $\hat{p}$ is $\mu$ = 0.7.

\pagebreak

## Variance of a Random Variable (Discrete Case)

The *variance* of a *discrete* random variable is
$$
  \sigma^2 = \sum_x (x - \mu)^2P(x),
$$
and the standard deviation is
$$
  \sigma = \sqrt{\sum_x (x - \mu)^2P(x)}.
$$

**Example**: Consider the probability distribution of an observation of a single throw of the trebuchet (a *population distribution*). 
```{r}
x <- 1:3
p <- c(0.1,0.3,0.6)
d <- expand.grid(x1 = x, x2 = x, x3 = x)
d$xbar <- apply(d, 1, mean)
d$prob <- apply(expand.grid(p1 = p, p2 = p, p3 = p), 1, prod)
d <- d %>% group_by(xbar) %>% summarize(prob = sum(prob))
d$label <- format(d$prob, nsmall = 3)
popdist <- data.frame(Distance = 1:3, Probability = p)
smpdist <- data.frame(Distance = round(d$xbar, 2), Probability = d$label)
names(popdist) <- c("$x$","$P(x)$")
names(smpdist) <- c("$\\bar{x}$", "$P(\\bar{x}$)")
ktbl(popdist)
m <- c(crossprod(x, p))
s <- sqrt(crossprod((x - m)^2, p))
```
Recall that the mean of the random variable $x$ is $\mu$ = `r m` m. We can confirm that the standard deviation of $x$ is $\sigma \approx$ `r round(s,2)` m.

\vspace{5cm}

**Example**: Consider the probability distribution of the mean distance of a sample of $n$ = 3 throws of the trebuchet (a *sampling distribution*).
```{r}
ktbl(smpdist)
m <- c(crossprod(d$xbar, d$prob))
s <- sqrt(crossprod((d$xbar - m)^2, d$prob))
```
The mean of $\bar{x}$ is $\mu$ = `r m` m. We can confirm that the standard deviation of $\bar{x}$ is $\sigma \approx$ `r round(s, 2)` m.
$$
  \sigma = \sqrt{(1 - 2.5)^2 \times 0.001 + (1.33 - 2.5)^2 \times 0.009 + (1.67 - 2.5)^2 \times 0.045 + \cdots + (3 - 2.5)^2 \times 0.216} \approx 0.39.
$$

